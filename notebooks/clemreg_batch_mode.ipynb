{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcfdc210",
   "metadata": {},
   "source": [
    "# Demonstration of CLEM-Reg running in batch mode\n",
    "This notebook demostrates how to use CLEM-Reg in a headless/batch mode configuration. A standalone python script that can be launched directly via the command line, with the same functionality, is also provided, for example to be submitted to a High Performance Computing (HPC) scheduler.\n",
    "\n",
    "## Data\n",
    "### Inputs\n",
    "The data we are using is associated with [this deposition in EMPIAR](https://www.ebi.ac.uk/empiar/EMPIAR-10819/), as presented in the CLEM-Reg manuscript. A sample dataset derived from this deposition is shared via zenodo [here](https://zenodo.org/records/7936982) so that it is accessible via the Sample Data menu in the napari GUI, and we use the same link to retrieve it in this notebook.\n",
    "\n",
    "### Outputs\n",
    "The notebook outputs a set of warped image files, with each warped channel saved as an individual output file, named with the convention `<CHANNEL_NAME>_warped.tif`. Output files are saved by default to WHERE_SAVED. \n",
    "\n",
    "## How to run this notebook\n",
    "INSERT GENERIC JUPYTER INSTRUCTIONS, OR LINK TO ONLINE INFO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a5d806-1e7e-4714-8c24-3a16b2a9beeb",
   "metadata": {},
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d46fc051-76e5-4bec-bb3e-d6dc60750165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari \n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from skimage.io import imread, imsave\n",
    "import torch\n",
    "\n",
    "from napari.layers import Labels, Points, Image\n",
    "from napari.experimental import link_layers\n",
    "\n",
    "from napari_clemreg.clemreg.log_segmentation import log_segmentation\n",
    "from napari_clemreg.clemreg.empanada_segmentation import empanada_segmentation\n",
    "from napari_clemreg.clemreg.sample_data import make_sample_data\n",
    "from napari_clemreg.clemreg.point_cloud_sampling import point_cloud_sampling\n",
    "from napari_clemreg.clemreg.point_cloud_registration import point_cloud_registration\n",
    "from napari_clemreg.clemreg.warp_image_volume import warp_image_volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac7298c-7ce0-44dd-9844-18118efdab8b",
   "metadata": {},
   "source": [
    "Check if there's a CUDA enabled GPU present, if not we won't run the EM segmentation step and use a pre-computed mask instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1745aad-1e15-4e01-a3b0-61dc4396eccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA found, so we'll use a pre-computed EM segmentation to save time\n"
     ]
    }
   ],
   "source": [
    "#has_gpu = torch.cuda.is_available()\n",
    "\n",
    "has_gpu = False # For testing, set to always false\n",
    "\n",
    "if has_gpu:\n",
    "    print(\"Found CUDA, so we'll run the full EM segmentation\")\n",
    "else:\n",
    "    print(\"No CUDA found, so we'll use a pre-computed EM segmentation to save time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1d22c7-8a95-411b-9b5f-d71692b3ed12",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "Here we run a function to download the `napari-clemreg` example data from zenodo. The function returns a tuple containing the data and metadata for one volume EM dataset and the corresponding fluorescence microscopy datasets to be aligned.\n",
    "\n",
    "We use napari's `Image` and `Labels` types to allow us to correctly propagate metadata in a way consistent with the napari plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f488fe-9f2d-44d5-a9d1-34b67f77361e",
   "metadata": {},
   "source": [
    "This cell prepares the input data as `Image` data objects. To test on different data, you can replace the file with a different path, ensuring you add the appropriate image voxel resolution via the `scale` argument to `Image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e5f338e-2f2c-4557-a09a-04e9fd06274a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EM...\n",
      "Loading FM...\n"
     ]
    }
   ],
   "source": [
    "em, tgn, lyso, mito, nuc = make_sample_data()  \n",
    "\n",
    "em_scale = [0.02, 0.02, 0.02]            # Note that the scales are provided in microns, \n",
    "lm_scale = [0.13, 0.0352740, 0.0352740]  # in the order [Z, Y, X] for both EM and LM data\n",
    "\n",
    "# Create napari \"Image\" objects with raw data and metadata\n",
    "em_image = Image(em[0], metadata=em[1], name='EM', scale=em_scale)\n",
    "fm_tgn   = Image(tgn[0], metadata=tgn[1], name='TGN', scale=lm_scale)\n",
    "fm_lyso  = Image(lyso[0], metadata=lyso[1], name='Lysosomes', scale=lm_scale)\n",
    "fm_mito  = Image(mito[0], metadata=mito[1], name='Mitochondria', scale=lm_scale)\n",
    "fm_nuc   = Image(nuc[0], metadata=nuc[1], name='Nucleus', scale=lm_scale)\n",
    "\n",
    "# Link the layers so that the transform is applied across all FM channels\n",
    "_ = link_layers([fm_tgn, fm_lyso, fm_mito, fm_nuc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f59ea9a-10e0-4aee-8d76-20f0f3c81c51",
   "metadata": {},
   "source": [
    "If we have a CUDA enabled GPU, we can run the EM segmentation, otherwise retrieve a pre-computed segmentation from the GitHub repository. Any appropriate segmentation function can be substituted here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833695f8-704d-453a-b332-69af5a6bbe1b",
   "metadata": {},
   "source": [
    "## Segmenting the data\n",
    "In case the user doesn't have a GPU, we've supplied the EM mask as created with MitoNet default settings in the napari plugin for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "175586ff-31a3-4ebc-bddd-a3340aff5b72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if has_gpu:\n",
    "    # Perform MitoNet segmentation\n",
    "    em_mask_data = empanada_segmentation(input=em_image.data, axis_prediction=False)\n",
    "else:\n",
    "    em_mask_file = \"data/em_mask.tif\"\n",
    "    em_mask_data = imread(em_mask_file)\n",
    "\n",
    "em_mask=Labels(np.uint16(em_mask_data), scale=em_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b456b24-6576-4367-aec2-905caa8975d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting Mitochondria with sigma=3 and threshold=1.2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmenting image..: 100%|████████████████████████████████████████████| 21/21 [00:00<00:00, 51.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished segmenting after 3.1820452213287354s!\n"
     ]
    }
   ],
   "source": [
    "fm_mito_mask_data = log_segmentation(fm_mito)\n",
    "# fm_mito_mask_metadata = {'name': 'mito_segmentation',\n",
    "#                          'metadata': {'XResolution': fm_mito.metadata['metadata']['XResolution'],\n",
    "#                          'YResolution': fm_mito.metadata['metadata']['YResolution']}}\n",
    "\n",
    "fm_mito_mask = Labels(fm_mito_mask_data, scale=lm_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb74f27-41cb-454a-a23b-8971cd90a1e2",
   "metadata": {},
   "source": [
    "## Point cloud sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8538e5ad-4a7d-46c1-b187-a3b8bd937914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling point cloud from Labels with voxel_size=15 and sampling_frequency=0.030303030303030304...\n",
      "Finished point cloud sampling after 15.0485360622406s!\n",
      "Sampling point cloud from fm_mito_mask_data with voxel_size=15 and sampling_frequency=0.030303030303030304...\n",
      "Finished point cloud sampling after 1.9133620262145996s!\n"
     ]
    }
   ],
   "source": [
    "em_points = point_cloud_sampling(em_mask, voxel_size=15, every_k_points=100//3, sigma=1.0)\n",
    "fm_points = point_cloud_sampling(fm_mito_mask, voxel_size=15, every_k_points=100//3, sigma=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f1915d-11d1-455d-b146-724b84b3f485",
   "metadata": {},
   "source": [
    "## Calculating the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd331056-40bb-4ef2-a71e-47e58c92447a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registering point clouds...: 100%|███████████████████████████████████| 50/50 [00:31<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  31.185267210006714\n",
      "result:  [[ 0.99998982 -0.0038598  -0.0023362 ]\n",
      " [ 0.00378351  0.99948642 -0.03182102]\n",
      " [ 0.00245782  0.03181185  0.99949085]] 1.706058339485949 [  24.89766269  -61.65528903 -324.51593298]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "moving_points_data, fixed_points_data, tf_moving_points_data, tf_data = point_cloud_registration(moving=fm_points, fixed=em_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d05d68fc-d89c-4906-82eb-07589e2cef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected result:  [[ 0.99998008 -0.00482832 -0.00406519]\n",
    "#  [ 0.00467302  0.99929012 -0.03738212]\n",
    "#  [ 0.00424279  0.03736237  0.99929278]] 0.9758678903218879 [   4.00501837  -62.06598641 -339.93251389]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "451055b5-f37b-41e6-a481-34a23f003083",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_points_kwargs = dict(\n",
    "    name='Moving_point_cloud',\n",
    "    face_color='red',\n",
    "    edge_color='black',\n",
    "    size=5,\n",
    "    metadata={'pxlsz': fm_mito_mask_metadata['metadata']['XResolution']}\n",
    ")\n",
    "\n",
    "fixed_points_kwargs = dict(\n",
    "    name='Fixed_point_cloud',\n",
    "    face_color='blue',\n",
    "    edge_color='black',\n",
    "    size=5,\n",
    "    metadata={'pxlsz': em_image.metadata['metadata']['XResolution'], 'output_shape': em_mask.data.shape}\n",
    ")\n",
    "\n",
    "moving_points = Points(moving_points_data, **moving_points_kwargs)\n",
    "fixed_points = Points(fixed_points_data, **fixed_points_kwargs)\n",
    "transformed_points = Points(moving_points_data, **moving_points_kwargs) # Duplicate of the original data...\n",
    "transformed_points.affine.affine_matrix = tf_data['affine']             # ...which we apply the transform to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843a2119-8c3d-4737-8eb7-6d0145015a8a",
   "metadata": {},
   "source": [
    "## Applying the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "92eb2217-75a9-44fe-9965-9820ae11d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_images = warp_image_volume(moving_image=fm_mito,\n",
    "                                  output_shape=em_image.data.shape,\n",
    "                                  transform_type='Rigid CPD',\n",
    "                                  moving_points=moving_points,\n",
    "                                  transformed_points=transformed_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a7ee4d0-a2b5-40f2-912a-74fcb249aed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving /Users/jonesma/Downloads/Lysosomes_warped.tif\n",
      "Saving /Users/jonesma/Downloads/Mitochondria_warped.tif\n",
      "Saving /Users/jonesma/Downloads/Nucleus_warped.tif\n",
      "Saving /Users/jonesma/Downloads/TGN_warped.tif\n"
     ]
    }
   ],
   "source": [
    "save_path_root = '/Users/jonesma/Downloads'   # CHANGE THIS TO A LOCATION OF YOUR CHOICE\n",
    "for warped_image in warped_images:\n",
    "    save_path = os.path.join(save_path_root, warped_image[1]['name']+'.tif')\n",
    "    print(f'Saving {save_path}')\n",
    "    imsave(save_path, warped_image[0], check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f596b939-86a8-411a-8f9b-5985c66ab213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-clemreg",
   "language": "python",
   "name": "napari-clemreg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
