{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcfdc210",
   "metadata": {},
   "source": [
    "# Demonstration of CLEM-Reg running in batch mode\n",
    "This notebook demostrates how to use CLEM-Reg in a headless/batch mode environment. A standalone python script that can be launched directly via the command line, with the same functionality, is also provided, for example to be submitted to a High Performance Computing (HPC) scheduler.\n",
    "\n",
    "## Data\n",
    "### Inputs\n",
    "The data we are using is associated with [this deposition in EMPIAR](https://www.ebi.ac.uk/empiar/EMPIAR-10819/), as presented in the CLEM-Reg manuscript. A sample dataset derived from this deposition is shared via zenodo [here](https://zenodo.org/records/7936982) so that it is accessible via the Sample Data menu in the napari GUI, and we use the same link to retrieve it in this notebook.\n",
    "\n",
    "### Outputs\n",
    "The notebook outputs a set of warped image files, with each warped channel saved as an individual output file, named with the convention `<CHANNEL_NAME>_warped.tif`. Output files are saved by default to WHERE_SAVED. \n",
    "\n",
    "## How to run this notebook\n",
    "INSERT GENERIC JUPYTER INSTRUCTIONS, OR LINK TO ONLINE INFO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a5d806-1e7e-4714-8c24-3a16b2a9beeb",
   "metadata": {},
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d46fc051-76e5-4bec-bb3e-d6dc60750165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np \n",
    "from skimage import metrics, measure\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import math\n",
    "import napari \n",
    "from scipy import ndimage \n",
    "import json\n",
    "from magicgui import magicgui\n",
    "import os\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.measure import label\n",
    "import torch\n",
    "\n",
    "from napari.layers import Labels, Points, Image\n",
    "from napari.types import PointsData\n",
    "from napari.experimental import link_layers\n",
    "\n",
    "from napari_clemreg.clemreg.widget_components import run_point_cloud_sampling, run_point_cloud_registration_and_warping\n",
    "from napari_clemreg.clemreg.log_segmentation import log_segmentation\n",
    "from napari_clemreg.clemreg.sample_data import make_sample_data\n",
    "from napari_clemreg.clemreg.point_cloud_sampling import point_cloud_sampling\n",
    "from napari_clemreg.clemreg.point_cloud_registration import point_cloud_registration\n",
    "from napari_clemreg.clemreg.warp_image_volume import warp_image_volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac7298c-7ce0-44dd-9844-18118efdab8b",
   "metadata": {},
   "source": [
    "Check if there's a CUDA enabled GPU present, if not we won't run the EM segmentation step and use a pre-computed mask instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1745aad-1e15-4e01-a3b0-61dc4396eccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA found, so we'll use a pre-computed EM segmentation to save time\n"
     ]
    }
   ],
   "source": [
    "#has_gpu = torch.cuda.is_available()\n",
    "\n",
    "has_gpu = False # For testing, set to always false\n",
    "\n",
    "if has_gpu:\n",
    "    print(\"Found CUDA, so we'll run the full EM segmentation\")\n",
    "else:\n",
    "    print(\"No CUDA found, so we'll use a pre-computed EM segmentation to save time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1d22c7-8a95-411b-9b5f-d71692b3ed12",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "Here we run a function to download the `napari-clemreg` example data from zenodo. The function returns a tuple containing the data and metadata for one volume EM dataset and the corresponding fluorescence microscopy datasets to be aligned.\n",
    "\n",
    "We use napari's `Image` and `Labels` types to allow us to correctly propagate metadata in a way consistent with the napari plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e5f338e-2f2c-4557-a09a-04e9fd06274a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EM...\n",
      "Loading FM...\n"
     ]
    }
   ],
   "source": [
    "em, tgn, lyso, mito, nuc = make_sample_data()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03afc99d-48c3-4e7d-bb35-a206829ac908",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_scale = [0.02, 0.02, 0.02]\n",
    "lm_scale = [0.13, 0.0352740, 0.0352740]\n",
    "\n",
    "em_raw = Image(em[0], metadata=em[1], name='EM', scale=em_scale)\n",
    "fm_tgn = Image(tgn[0], metadata=tgn[1], name='TGN', scale=lm_scale)\n",
    "fm_lyso = Image(lyso[0], metadata=lyso[1], name='Lysosomes', scale=lm_scale)\n",
    "fm_mito = Image(mito[0], metadata=mito[1], name='Mitochondria', scale=lm_scale)\n",
    "fm_nuc = Image(nuc[0], metadata=nuc[1], name='Nucleus', scale=lm_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6a4c98d-a4c0-47b0-900d-b57f1f476af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02, 0.02, 0.02])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_raw.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2dfdef0-b418-42c1-b789-8581efff5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = link_layers([fm_tgn, fm_lyso, fm_mito, fm_nuc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f59ea9a-10e0-4aee-8d76-20f0f3c81c51",
   "metadata": {},
   "source": [
    "If we have a CUDA enabled GPU, we can run the EM segmentation, otherwise retrieve a pre-computed segmentation from the GitHub repository. Any appropriate segmentation function can be substituted here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "175586ff-31a3-4ebc-bddd-a3340aff5b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_gpu:\n",
    "    pass\n",
    "else:\n",
    "    em_mask_file = \"data/em_mask.tif\"\n",
    "    em_mask_metadata = {'name': 'EM mask',\n",
    "                        'metadata': {'ImageDescription': '\\nunit=micron\\nspacing=0.02\\n',\n",
    "                        'XResolution': 50,\n",
    "                        'YResolution': 50}}\n",
    "    em_mask_data = np.uint16(imread(em_mask_file))\n",
    "    em_mask = Labels(em_mask_data, metadata=em_mask_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833695f8-704d-453a-b332-69af5a6bbe1b",
   "metadata": {},
   "source": [
    "## Segmenting the data\n",
    "In case the user doesn't have a GPU, we've supplied the EM mask as created with MitoNet default settings in the napari plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b456b24-6576-4367-aec2-905caa8975d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting Image with sigma=3 and threshold=1.2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmenting image..: 100%|███████████████████████| 21/21 [00:00<00:00, 64.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished segmenting after 3.0206220149993896s!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fm_mito_mask_data = log_segmentation(Image(fm_mito.data,metadata=fm_mito.metadata))\n",
    "fm_mito_mask_metadata = {'name': 'mito_segmentation',\n",
    "                         'metadata': {'XResolution': fm_mito.metadata['metadata']['XResolution'],\n",
    "                         'YResolution': fm_mito.metadata['metadata']['YResolution']}}\n",
    "\n",
    "fm_mito_mask = Labels(fm_mito_mask_data, metadata=fm_mito_mask_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb74f27-41cb-454a-a23b-8971cd90a1e2",
   "metadata": {},
   "source": [
    "## Point cloud sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8538e5ad-4a7d-46c1-b187-a3b8bd937914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling point cloud from em_mask_data with voxel_size=15 and sampling_frequency=0.030303030303030304...\n",
      "Finished point cloud sampling after 13.140029907226562s!\n",
      "Sampling point cloud from fm_mito_mask_data with voxel_size=15 and sampling_frequency=0.030303030303030304...\n",
      "Finished point cloud sampling after 1.6992969512939453s!\n"
     ]
    }
   ],
   "source": [
    "em_points = point_cloud_sampling(em_mask, voxel_size=15, every_k_points=100//3, sigma=1.0)\n",
    "fm_points = point_cloud_sampling(fm_mito_mask, voxel_size=15, every_k_points=100//3, sigma=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f1915d-11d1-455d-b146-724b84b3f485",
   "metadata": {},
   "source": [
    "## Calculating the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd331056-40bb-4ef2-a71e-47e58c92447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registering point clouds...: 100%|██████████████| 50/50 [00:23<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  24.13033390045166\n",
      "result:  [[ 0.99999287 -0.00336532 -0.00171148]\n",
      " [ 0.00331545  0.99959258 -0.0283494 ]\n",
      " [ 0.00180619  0.02834353  0.99959661]] 1.700506779813002 [  24.18414179  -62.74540248 -319.09710725]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "moving_points_data, fixed_points_data, tf_moving_points_data, tf_data = point_cloud_registration(moving=fm_points, fixed=em_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "451055b5-f37b-41e6-a481-34a23f003083",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_points_kwargs = dict(\n",
    "    name='Moving_point_cloud',\n",
    "    face_color='red',\n",
    "    edge_color='black',\n",
    "    size=5,\n",
    "    metadata={'pxlsz': fm_mito_mask_metadata['metadata']['XResolution']}\n",
    ")\n",
    "\n",
    "fixed_points_kwargs = dict(\n",
    "    name='Fixed_point_cloud',\n",
    "    face_color='blue',\n",
    "    edge_color='black',\n",
    "    size=5,\n",
    "    metadata={'pxlsz': em_raw.metadata['metadata']['XResolution'], 'output_shape': em_mask.data.shape}\n",
    ")\n",
    "\n",
    "moving_points = Points(moving_points_data, **moving_points_kwargs)\n",
    "fixed_points = Points(fixed_points_data, **fixed_points_kwargs)\n",
    "transformed_points = Points(moving_points_data, **moving_points_kwargs) # Duplicate of the original data...\n",
    "transformed_points.affine.affine_matrix = tf_data['affine']             # ...which we apply the transform to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843a2119-8c3d-4737-8eb7-6d0145015a8a",
   "metadata": {},
   "source": [
    "## Applying the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92eb2217-75a9-44fe-9965-9820ae11d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_images = warp_image_volume(moving_image=fm_mito,\n",
    "                                  output_shape=em_raw.data.shape,\n",
    "                                  transform_type='Rigid CPD',\n",
    "                                  moving_points=moving_points,\n",
    "                                  transformed_points=transformed_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a7ee4d0-a2b5-40f2-912a-74fcb249aed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving /Users/jonesma/Downloads/Nucleus_warped.tif\n",
      "Saving /Users/jonesma/Downloads/Lysosomes_warped.tif\n",
      "Saving /Users/jonesma/Downloads/TGN_warped.tif\n",
      "Saving /Users/jonesma/Downloads/Mitochondria_warped.tif\n"
     ]
    }
   ],
   "source": [
    "save_path_root = '/Users/jonesma/Downloads'   # CHANGE THIS TO A LOCATION OF YOUR CHOICE\n",
    "for warped_image in warped_images:\n",
    "    save_path = os.path.join(save_path_root, warped_image[1]['name']+'.tif')\n",
    "    print(f'Saving {save_path}')\n",
    "    imsave(save_path, warped_image[0], check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f596b939-86a8-411a-8f9b-5985c66ab213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
